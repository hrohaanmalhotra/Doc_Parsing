{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a5b467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-docx) (4.6.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hroha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06354023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    doc = Document(docx_file)\n",
    "    \n",
    "    # Extract comments\n",
    "    comments = []\n",
    "    for comment in doc.comments:\n",
    "        comments.append({\n",
    "            'author': comment.author,\n",
    "            'text': comment.text\n",
    "        })\n",
    "    \n",
    "    # Extract highlighted text\n",
    "    highlighted_text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_text.append(run.text)\n",
    "    \n",
    "    return comments, highlighted_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dfccc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHLIGHTED TEXT:\n",
      " software \n",
      ". Wikipedia is the largest and most-read \n",
      " in history,\n",
      " and is consistently ranked among the ten \n",
      "; as of May 2024, it was ranked fourth by \n",
      ",\n",
      " and sixth by \n",
      ".\n",
      " Founded by \n",
      " and \n",
      " on January 15, 2001, Wikipedia has been hosted since 2003 by the \n",
      ", an American \n",
      " funded mainly by donations from readers.\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_highlighted_text(docx_file):\n",
    "    doc = Document(docx_file)\n",
    "    \n",
    "    highlighted_text = []\n",
    "    \n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_text.append(run.text)\n",
    "    \n",
    "    return highlighted_text\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document.docx'\n",
    "    highlighted_text = extract_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"HIGHLIGHTED TEXT:\")\n",
    "    for text in highlighted_text:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa29a257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENTS:\n",
      "Comment ID: 1\n",
      "Author: Hrohaan Malhotra\n",
      "Date: 2024-06-17T05:41:59Z\n",
      "Text: This is comment number 2\n",
      "\n",
      "Comment ID: 0\n",
      "Author: Hrohaan Malhotra\n",
      "Date: 2024-06-17T05:41:43Z\n",
      "Text: This is a Comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "\n",
    "def extract_comments(docx_file):\n",
    "    comments = []\n",
    "\n",
    "    # Open the docx file as a zip archive\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        # Check if 'word/comments.xml' exists in the zip file\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                # Parse the XML using lxml\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                # Find all comments in the document\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    # Extract text of the comment\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    comments.append({\n",
    "                        'id': comment_id,\n",
    "                        'author': author,\n",
    "                        'date': date,\n",
    "                        'text': comment_text\n",
    "                    })\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document.docx'\n",
    "    comments = extract_comments(docx_file)\n",
    "    \n",
    "    print(\"COMMENTS:\")\n",
    "    for comment in comments:\n",
    "        print(f\"Comment ID: {comment['id']}\")\n",
    "        print(f\"Author: {comment['author']}\")\n",
    "        print(f\"Date: {comment['date']}\")\n",
    "        print(f\"Text: {comment['text']}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1362956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENTS:\n",
      "      Type ID            Author                  Date  \\\n",
      "0  Comment  1  Hrohaan Malhotra  2024-06-17T05:41:59Z   \n",
      "1  Comment  0  Hrohaan Malhotra  2024-06-17T05:41:43Z   \n",
      "\n",
      "                       Text  \n",
      "0  This is comment number 2  \n",
      "1         This is a Comment  \n",
      "\n",
      "HIGHLIGHTED TEXT:\n",
      "                Type                                               Text\n",
      "0   Highlighted Text                                          software \n",
      "1   Highlighted Text          . Wikipedia is the largest and most-read \n",
      "2   Highlighted Text                                        in history,\n",
      "3   Highlighted Text          and is consistently ranked among the ten \n",
      "4   Highlighted Text         ; as of May 2024, it was ranked fourth by \n",
      "5   Highlighted Text                                                  ,\n",
      "6   Highlighted Text                                      and sixth by \n",
      "7   Highlighted Text                                                  .\n",
      "8   Highlighted Text                                        Founded by \n",
      "9   Highlighted Text                                               and \n",
      "10  Highlighted Text   on January 15, 2001, Wikipedia has been hoste...\n",
      "11  Highlighted Text                                     , an American \n",
      "12  Highlighted Text           funded mainly by donations from readers.\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    comments = []\n",
    "    highlighted_text = []\n",
    "\n",
    "    # Extract comments using lxml\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    comments.append({\n",
    "                        'Type': 'Comment',\n",
    "                        'ID': comment_id,\n",
    "                        'Author': author,\n",
    "                        'Date': date,\n",
    "                        'Text': comment_text\n",
    "                    })\n",
    "\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    # Extract highlighted text using python-docx\n",
    "    doc = Document(docx_file)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_text.append({\n",
    "                    'Type': 'Highlighted Text',\n",
    "                    'Text': run.text\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df_comments = pd.DataFrame(comments)\n",
    "    df_highlighted_text = pd.DataFrame(highlighted_text)\n",
    "    \n",
    "    return df_comments, df_highlighted_text\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document.docx'\n",
    "    df_comments, df_highlighted_text = extract_comments_and_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"COMMENTS:\")\n",
    "    print(df_comments)\n",
    "    print()\n",
    "    \n",
    "    print(\"HIGHLIGHTED TEXT:\")\n",
    "    print(df_highlighted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff30e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENTS AND HIGHLIGHTED TEXT:\n",
      "                Type    ID            Author                  Date  \\\n",
      "0            Comment     1  Hrohaan Malhotra  2024-06-17T05:41:59Z   \n",
      "1            Comment     0  Hrohaan Malhotra  2024-06-17T05:41:43Z   \n",
      "2   Highlighted Text  None              None                  None   \n",
      "3   Highlighted Text  None              None                  None   \n",
      "4   Highlighted Text  None              None                  None   \n",
      "5   Highlighted Text  None              None                  None   \n",
      "6   Highlighted Text  None              None                  None   \n",
      "7   Highlighted Text  None              None                  None   \n",
      "8   Highlighted Text  None              None                  None   \n",
      "9   Highlighted Text  None              None                  None   \n",
      "10  Highlighted Text  None              None                  None   \n",
      "11  Highlighted Text  None              None                  None   \n",
      "12  Highlighted Text  None              None                  None   \n",
      "13  Highlighted Text  None              None                  None   \n",
      "14  Highlighted Text  None              None                  None   \n",
      "\n",
      "                                                 Text  \n",
      "0                            This is comment number 2  \n",
      "1                                   This is a Comment  \n",
      "2                                           software   \n",
      "3           . Wikipedia is the largest and most-read   \n",
      "4                                         in history,  \n",
      "5           and is consistently ranked among the ten   \n",
      "6          ; as of May 2024, it was ranked fourth by   \n",
      "7                                                   ,  \n",
      "8                                       and sixth by   \n",
      "9                                                   .  \n",
      "10                                        Founded by   \n",
      "11                                               and   \n",
      "12   on January 15, 2001, Wikipedia has been hoste...  \n",
      "13                                     , an American   \n",
      "14           funded mainly by donations from readers.  \n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    data = []\n",
    "\n",
    "    # Extract comments using lxml\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    data.append({\n",
    "                        'Type': 'Comment',\n",
    "                        'ID': comment_id,\n",
    "                        'Author': author,\n",
    "                        'Date': date,\n",
    "                        'Text': comment_text\n",
    "                    })\n",
    "\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    # Extract highlighted text using python-docx\n",
    "    doc = Document(docx_file)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                data.append({\n",
    "                    'Type': 'Highlighted Text',\n",
    "                    'ID': None,\n",
    "                    'Author': None,\n",
    "                    'Date': None,\n",
    "                    'Text': run.text\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document.docx'\n",
    "    df = extract_comments_and_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"COMMENTS AND HIGHLIGHTED TEXT:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57cb4cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>Hrohaan Malhotra</td>\n",
       "      <td>2024-06-17T05:41:59Z</td>\n",
       "      <td>This is comment number 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type ID            Author                  Date  \\\n",
       "0  Comment  1  Hrohaan Malhotra  2024-06-17T05:41:59Z   \n",
       "\n",
       "                       Text  \n",
       "0  This is comment number 2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f093c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHLIGHTED TEXT AND COMMENTS PAIRS:\n",
      "                                    Highlighted_Text  \\\n",
      "0  That’s why this moment on the internet feels e...   \n",
      "1  It’s easy to name a root cause — ads reward an...   \n",
      "2  Now we have decades of proof that attention-gr...   \n",
      "3  Everything Medium does is paid for by our memb...   \n",
      "\n",
      "               Comment Text    Comment Author          Comment Date  \n",
      "0         This is comment 4  Hrohaan Malhotra  2024-06-17T05:58:41Z  \n",
      "1  This is comment number 3  Hrohaan Malhotra  2024-06-17T05:58:32Z  \n",
      "2  This is Comment number 2  Hrohaan Malhotra  2024-06-17T05:58:20Z  \n",
      "3  This is comment number 1  Hrohaan Malhotra  2024-06-17T05:58:09Z  \n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    data = []\n",
    "\n",
    "    # Extract comments using lxml\n",
    "    comments = {}\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    comments[comment_id] = {\n",
    "                        'Author': author,\n",
    "                        'Date': date,\n",
    "                        'Text': comment_text\n",
    "                    }\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    # Extract highlighted text and match it to comments\n",
    "    doc = Document(docx_file)\n",
    "    highlighted_texts = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_texts.append(run.text)\n",
    "\n",
    "    # Pair highlighted text with comments\n",
    "    for i, (comment_id, comment_data) in enumerate(comments.items()):\n",
    "        if i < len(highlighted_texts):\n",
    "            data.append({\n",
    "                'Highlighted_Text': highlighted_texts[i],\n",
    "                'Comment Text': comment_data['Text'],\n",
    "                'Comment Author': comment_data['Author'],\n",
    "                'Comment Date': comment_data['Date']\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'Highlighted_Text': 'N/A',\n",
    "                'Comment Text': comment_data['Text'],\n",
    "                'Comment Author': comment_data['Author'],\n",
    "                'Comment Date': comment_data['Date']\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document2.docx'\n",
    "    df = extract_comments_and_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"HIGHLIGHTED TEXT AND COMMENTS PAIRS:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7b052ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s easy to name a root cause — ads reward any content that can grab your attention long enough to show you yet another ad, and the more the better.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Highlighted_Text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c1aa374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That’s why this moment on the internet feels even more urgent than normal. Even before Google used AI to tell us to (really!), search results were already flooded with content that was written by or for machines, not humans.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Highlighted_Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2563fd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we have decades of proof that attention-grabbing isn’t the same as good. Instead of the information superhighway that we were promised, ads gave us an internet where almost all incentives are to create cheap, high-volume, low-quality content designed to get as many eyeballs as possible.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Highlighted_Text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf0da978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything Medium does is paid for by our members, not advertising. We’re not trying to manipulate your attention to show you more ads. Instead, we care about a much harder challenge: How can we show you a story that you will be happy to have paid to read?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Highlighted_Text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45eef60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHLIGHTED TEXT AND COMMENTS PAIRS:\n",
      "                                    Highlighted Text  \\\n",
      "0  That’s why this moment on the internet feels e...   \n",
      "1  It’s easy to name a root cause — ads reward an...   \n",
      "2  Now we have decades of proof that attention-gr...   \n",
      "3  Everything Medium does is paid for by our memb...   \n",
      "\n",
      "               Comment Text    Comment Author          Comment Date  \n",
      "0  This is comment number 1  Hrohaan Malhotra  2024-06-17T05:58:09Z  \n",
      "1  This is Comment number 2  Hrohaan Malhotra  2024-06-17T05:58:20Z  \n",
      "2  This is comment number 3  Hrohaan Malhotra  2024-06-17T05:58:32Z  \n",
      "3         This is comment 4  Hrohaan Malhotra  2024-06-17T05:58:41Z  \n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    data = []\n",
    "\n",
    "    # Extract comments using lxml\n",
    "    comments = []\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    comments.append({\n",
    "                        'ID': comment_id,\n",
    "                        'Author': author,\n",
    "                        'Date': date,\n",
    "                        'Text': comment_text\n",
    "                    })\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    # Extract highlighted text using python-docx\n",
    "    highlighted_texts = []\n",
    "    doc = Document(docx_file)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_texts.append(run.text)\n",
    "\n",
    "    # Reverse the comments list\n",
    "    comments.reverse()\n",
    "\n",
    "    # Pair highlighted text with comments\n",
    "    for i in range(max(len(highlighted_texts), len(comments))):\n",
    "        if i < len(highlighted_texts) and i < len(comments):\n",
    "            data.append({\n",
    "                'Highlighted Text': highlighted_texts[i],\n",
    "                'Comment Text': comments[i]['Text'],\n",
    "                'Comment Author': comments[i]['Author'],\n",
    "                'Comment Date': comments[i]['Date']\n",
    "            })\n",
    "        elif i < len(highlighted_texts):\n",
    "            data.append({\n",
    "                'Highlighted Text': highlighted_texts[i],\n",
    "                'Comment Text': 'N/A',\n",
    "                'Comment Author': 'N/A',\n",
    "                'Comment Date': 'N/A'\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'Highlighted Text': 'N/A',\n",
    "                'Comment Text': comments[i]['Text'],\n",
    "                'Comment Author': comments[i]['Author'],\n",
    "                'Comment Date': comments[i]['Date']\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document2.docx'\n",
    "    df = extract_comments_and_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"HIGHLIGHTED TEXT AND COMMENTS PAIRS:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd617941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8aea371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHLIGHTED TEXT AND COMMENTS PAIRS:\n",
      "                                    Highlighted Text  \\\n",
      "0  That’s why this moment on the internet feels e...   \n",
      "1  It’s easy to name a root cause — ads reward an...   \n",
      "2  Now we have decades of proof that attention-gr...   \n",
      "3  Everything Medium does is paid for by our memb...   \n",
      "4  That’s why this moment on the internet feels e...   \n",
      "5  It’s easy to name a root cause — ads reward an...   \n",
      "6  Now we have decades of proof that attention-gr...   \n",
      "7  Everything Medium does is paid for by our memb...   \n",
      "\n",
      "               Comment Text    Comment Author          Comment Date  \n",
      "0                       N/A               N/A                   N/A  \n",
      "1                       N/A               N/A                   N/A  \n",
      "2                       N/A               N/A                   N/A  \n",
      "3                       N/A               N/A                   N/A  \n",
      "4  This is comment number 1  Hrohaan Malhotra  2024-06-17T05:58:09Z  \n",
      "5  This is Comment number 2  Hrohaan Malhotra  2024-06-17T05:58:20Z  \n",
      "6         This is comment 4  Hrohaan Malhotra  2024-06-17T05:58:41Z  \n",
      "7  This is comment number 3  Hrohaan Malhotra  2024-06-17T05:58:32Z  \n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    data = []\n",
    "\n",
    "    # Extract comments using lxml\n",
    "    comments = {}\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    comments[comment_id] = {\n",
    "                        'Author': author,\n",
    "                        'Date': date,\n",
    "                        'Text': comment_text\n",
    "                    }\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    # Extract highlighted text and match it to comments\n",
    "    highlighted_texts = []\n",
    "    doc = Document(docx_file)\n",
    "    comment_index = 0\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_texts.append({\n",
    "                    'Highlighted Text': run.text,\n",
    "                    'Comment ID': None\n",
    "                })\n",
    "\n",
    "    # Read main document XML to map comments to text\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/document.xml' in zipf.namelist():\n",
    "            with zipf.open('word/document.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                current_comment_id = None\n",
    "                for elem in root.iter():\n",
    "                    if elem.tag.endswith('commentRangeStart'):\n",
    "                        current_comment_id = elem.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', None)\n",
    "                    elif elem.tag.endswith('commentRangeEnd'):\n",
    "                        current_comment_id = None\n",
    "                    elif elem.tag.endswith('r') and current_comment_id:\n",
    "                        for t in elem.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                            if t.text:\n",
    "                                highlighted_texts.append({\n",
    "                                    'Highlighted Text': t.text,\n",
    "                                    'Comment ID': current_comment_id\n",
    "                                })\n",
    "\n",
    "    # Pair highlighted text with comments\n",
    "    for highlighted in highlighted_texts:\n",
    "        comment_id = highlighted['Comment ID']\n",
    "        if comment_id and comment_id in comments:\n",
    "            data.append({\n",
    "                'Highlighted Text': highlighted['Highlighted Text'],\n",
    "                'Comment Text': comments[comment_id]['Text'],\n",
    "                'Comment Author': comments[comment_id]['Author'],\n",
    "                'Comment Date': comments[comment_id]['Date']\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'Highlighted Text': highlighted['Highlighted Text'],\n",
    "                'Comment Text': 'N/A',\n",
    "                'Comment Author': 'N/A',\n",
    "                'Comment Date': 'N/A'\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document2.docx'\n",
    "    df = extract_comments_and_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"HIGHLIGHTED TEXT AND COMMENTS PAIRS:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64a0a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHLIGHTED TEXT AND COMMENTS PAIRS:\n",
      "                                    Highlighted Text  \\\n",
      "0  That’s why this moment on the internet feels e...   \n",
      "1  It’s easy to name a root cause — ads reward an...   \n",
      "2  Now we have decades of proof that attention-gr...   \n",
      "3  Everything Medium does is paid for by our memb...   \n",
      "\n",
      "               Comment Text    Comment Author          Comment Date  \n",
      "0  This is comment number 1  Hrohaan Malhotra  2024-06-17T05:58:09Z  \n",
      "1  This is Comment number 2  Hrohaan Malhotra  2024-06-17T05:58:20Z  \n",
      "2         This is comment 4  Hrohaan Malhotra  2024-06-17T05:58:41Z  \n",
      "3  This is comment number 3  Hrohaan Malhotra  2024-06-17T05:58:32Z  \n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "def extract_comments_and_highlighted_text(docx_file):\n",
    "    data = []\n",
    "    comments = {}\n",
    "    highlighted_texts = []\n",
    "\n",
    "    # Extract comments using lxml\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/comments.xml' in zipf.namelist():\n",
    "            with zipf.open('word/comments.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for comment in root.findall('.//w:comment', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                    comment_id = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', '')\n",
    "                    author = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}author', '')\n",
    "                    date = comment.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}date', '')\n",
    "\n",
    "                    comment_text = \"\"\n",
    "                    for text_element in comment.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                        if text_element.text:\n",
    "                            comment_text += text_element.text\n",
    "\n",
    "                    comments[comment_id] = {\n",
    "                        'Author': author,\n",
    "                        'Date': date,\n",
    "                        'Text': comment_text\n",
    "                    }\n",
    "        else:\n",
    "            print(\"No comments.xml found in the document.\")\n",
    "\n",
    "    # Extract highlighted text and match it to comments\n",
    "    doc = Document(docx_file)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            if run.font.highlight_color == WD_COLOR_INDEX.YELLOW:  # Adjust as needed\n",
    "                highlighted_texts.append({\n",
    "                    'Highlighted Text': run.text,\n",
    "                    'Comment ID': None\n",
    "                })\n",
    "\n",
    "    # Read main document XML to map comments to text\n",
    "    with ZipFile(docx_file, 'r') as zipf:\n",
    "        if 'word/document.xml' in zipf.namelist():\n",
    "            with zipf.open('word/document.xml') as f:\n",
    "                tree = etree.parse(f)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                current_comment_id = None\n",
    "                for elem in root.iter():\n",
    "                    if elem.tag.endswith('commentRangeStart'):\n",
    "                        current_comment_id = elem.attrib.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id', None)\n",
    "                    elif elem.tag.endswith('commentRangeEnd'):\n",
    "                        current_comment_id = None\n",
    "                    elif elem.tag.endswith('r') and current_comment_id:\n",
    "                        for t in elem.findall('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}):\n",
    "                            if t.text:\n",
    "                                highlighted_texts.append({\n",
    "                                    'Highlighted Text': t.text,\n",
    "                                    'Comment ID': current_comment_id\n",
    "                                })\n",
    "\n",
    "    # Create a dictionary to avoid duplicates\n",
    "    highlighted_texts_dict = {text['Highlighted Text']: text['Comment ID'] for text in highlighted_texts}\n",
    "\n",
    "    # Pair highlighted text with comments\n",
    "    for highlighted_text, comment_id in highlighted_texts_dict.items():\n",
    "        if comment_id and comment_id in comments:\n",
    "            data.append({\n",
    "                'Highlighted Text': highlighted_text,\n",
    "                'Comment Text': comments[comment_id]['Text'],\n",
    "                'Comment Author': comments[comment_id]['Author'],\n",
    "                'Comment Date': comments[comment_id]['Date']\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'Highlighted Text': highlighted_text,\n",
    "                'Comment Text': 'N/A',\n",
    "                'Comment Author': 'N/A',\n",
    "                'Comment Date': 'N/A'\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    docx_file = 'Document2.docx'\n",
    "    df = extract_comments_and_highlighted_text(docx_file)\n",
    "    \n",
    "    print(\"HIGHLIGHTED TEXT AND COMMENTS PAIRS:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30732eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
